{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eviris_myproject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafaKhalil-IST/eviris-dataset-group7/blob/master/eviris_myproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQBOxVpKs3jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ddef0b89-ae72-43ca-b5ae-ffa447243ba6"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from keras.engine.topology import Layer\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import numpy.random as rng"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bZmQy52uFMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = './fruits/fruits-360/Training'\n",
        "validation = './fruits/fruits-360/Validation'\n",
        "test = './fruits/fruits-360/Test'\n",
        "save_path = './data/'\n",
        "model_path = './weights/'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7081tWX0pZC",
        "colab_type": "text"
      },
      "source": [
        "use datagen instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYcIcEccuTlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(path,n = 0):\n",
        "    X, y, classes = [], [], []\n",
        "    y_cat = 0\n",
        "    for category in os.listdir(path):\n",
        "        classes.append(category)\n",
        "        print(\"loading category: \" + category)\n",
        "        category_path = os.path.join(path,category)\n",
        "        print('Found ' + str(len(os.listdir(category_path))) + ' images')\n",
        "        for image in os.listdir(category_path):\n",
        "            image_path = os.path.join(category_path, image)\n",
        "            image = cv2.imread(image_path)\n",
        "            X.append(image)\n",
        "            y.append(y_cat)\n",
        "        y_cat += 1\n",
        "    classes = np.vstack(classes)\n",
        "    y = np.vstack(y)\n",
        "    X = np.stack(X)\n",
        "    return X, y, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej39bZv_kqlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "0b28bd98-5fdc-48d4-d805-cb790f2a3a44"
      },
      "source": [
        "X, y, classes = generate_data(train)\n",
        "Xval, yval, classesval = generate_data(validation)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading category: Pear\n",
            "Found 3228 images\n",
            "loading category: Orange\n",
            "Found 479 images\n",
            "loading category: Lemon\n",
            "Found 982 images\n",
            "loading category: Apple\n",
            "Found 6416 images\n",
            "loading category: Pear\n",
            "Found 493 images\n",
            "loading category: Orange\n",
            "Found 40 images\n",
            "loading category: Lemon\n",
            "Found 165 images\n",
            "loading category: Apple\n",
            "Found 1068 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-apCDb9lEN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(save_path):\n",
        "  os.mkdir(save_path)\n",
        "\n",
        "with open(os.path.join(save_path,\"train.pickle\"), \"wb\") as f:\n",
        "    pickle.dump((X,y,classes),f)\n",
        "    \n",
        "with open(os.path.join(save_path,\"val.pickle\"), \"wb\") as f:\n",
        "    pickle.dump((Xval,yval,classesval),f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNNd_IbpxIjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_weights(shape):\n",
        "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MigAWJHnxTEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_bias(shape):\n",
        "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6EQhzjNxdqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_shape):\n",
        "  \n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
        "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (7,7), activation='relu',\n",
        "                     kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='sigmoid',\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the two images\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "    # return the model\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXggyFgzxxdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "bc8ee909-0018-43ac-c95e-88bd95743496"
      },
      "source": [
        "model = create_model((100, 100, 3))\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 100, 100, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 100, 100, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 4096)         27426112    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 27,430,209\n",
            "Trainable params: 27,430,209\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCtL1p5sx_do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=Adam(lr = 0.00006))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T8n11KiyVZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "b00874da-6d06-48b4-d2fb-8988646cae5f"
      },
      "source": [
        "with open(os.path.join(save_path, \"train.pickle\"), \"rb\") as f:\n",
        "    (Xtrain, ytrain, train_classes) = pickle.load(f)\n",
        "    \n",
        "print(\"Training classes: \\n\")\n",
        "print(train_classes)\n",
        "\n",
        "with open(os.path.join(save_path, \"val.pickle\"), \"rb\") as f:\n",
        "    (Xval, yval, val_classes) = pickle.load(f)\n",
        "\n",
        "print(\"Validation classes:\", end=\"\\n\\n\")\n",
        "print(val_classes)\n",
        "\n",
        "print(Xtrain.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training classes: \n",
            "\n",
            "[['Pear']\n",
            " ['Orange']\n",
            " ['Lemon']\n",
            " ['Apple']]\n",
            "Validation classes:\n",
            "\n",
            "[['Pear']\n",
            " ['Orange']\n",
            " ['Lemon']\n",
            " ['Apple']]\n",
            "(11105, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O760QNnn6HQZ",
        "colab_type": "text"
      },
      "source": [
        "Use fit_generator instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORFw590Myz0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper parameters\n",
        "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
        "n_iter = 20000 # No. of training iterations\n",
        "N_way = 20 # how many classes for testing one-shot tasks\n",
        "n_val = 250 # how many one-shot tasks to validate on\n",
        "best = -1\n",
        "epochs = 5\n",
        "img_width, img_height = 100, 100\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQghAlFiQg-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_batch(batch_size, batch_type=\"train\"):\n",
        "    if batch_type == 'train':\n",
        "        X = Xtrain\n",
        "        categories = train_classes\n",
        "    else:\n",
        "        X = Xval\n",
        "        categories = val_classes\n",
        "    \n",
        "    n_classes = len(categories)\n",
        "    n_examples, w, h, _ = X.shape\n",
        "    \n",
        "    idx_base = n_examples//n_classes\n",
        "    \n",
        "    pairs=[np.zeros((batch_size, w, h, 3)) for i in range(2)]\n",
        "    \n",
        "    targets=np.zeros((batch_size,))\n",
        "    targets[batch_size//2:] = 1\n",
        "    \n",
        "    for i in range(batch_size//2):\n",
        "      pairs[0][i] = X[idx_base * np.random.randint(0,4)]\n",
        "      pairs[1][i] = X[idx_base * ((np.random.randint(0,4)+1)%4)]\n",
        "      \n",
        "      if i == 0:\n",
        "        plt.imshow(pairs[0][i])\n",
        "        plt.imshow(pairs[1][i])\n",
        "        plt.show()\n",
        "        \n",
        "    for i in range(batch_size//2,batch_size):\n",
        "      idx = np.random.randint(0,4)\n",
        "      pairs[0][i] = X[idx_base * idx + np.random.randint(0,batch_size)]\n",
        "      pairs[1][i] = X[idx_base * idx + np.random.randint(0,batch_size)]\n",
        "      \n",
        "      if i == batch_size//2:\n",
        "        plt.imshow(pairs[0][i])\n",
        "        plt.imshow(pairs[1][i])\n",
        "        plt.show()\n",
        "        \n",
        "    return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h00sj21QtY5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11910
        },
        "outputId": "4c603c46-7e3f-432f-e9f2-e16a9119c76d"
      },
      "source": [
        "prepare_batch(32)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1ND/AhALpQd1wyW3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1ND/AhALpQd1wyW3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         [[[250., 255., 253.],\n",
              "           [251., 255., 254.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[253., 255., 254.],\n",
              "           [253., 255., 254.],\n",
              "           [253., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[254., 254., 254.],\n",
              "           [253., 255., 255.],\n",
              "           [250., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]]]), array([[[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 254.],\n",
              "           [255., 255., 254.],\n",
              "           [255., 255., 254.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 254.],\n",
              "           [255., 255., 254.],\n",
              "           [255., 255., 254.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 254.],\n",
              "           [255., 255., 254.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]],\n",
              "  \n",
              "  \n",
              "         [[[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]],\n",
              "  \n",
              "          [[255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           ...,\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.],\n",
              "           [255., 255., 255.]]]])],\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNzeBj7evSEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches(batch_size, s=\"train\"):\n",
        "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
        "    while True:\n",
        "        pairs, targets = get_batch(batch_size,s)\n",
        "        yield (pairs, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSXx0hQDvX-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_oneshot_task(N, s=\"val\"):\n",
        "    \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
        "    if s == 'train':\n",
        "        X = Xtrain\n",
        "        categories = train_classes\n",
        "    else:\n",
        "        X = Xval\n",
        "        categories = val_classes\n",
        "    \n",
        "    n_examples, w, h, _ = X.shape\n",
        "    \n",
        "    indices = np.random.randint(0, n_examples,size=(N,))\n",
        "    \n",
        "    categories = np.random.choice(range(n_classes),size=(N,),replace=False)            \n",
        "    \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = np.random.choice(n_examples,replace=False,size=(2,))\n",
        "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
        "    support_set = X[categories,indices,:,:]\n",
        "    support_set[0,:,:] = X[true_category,ex2]\n",
        "    support_set = support_set.reshape(N, w, h,1)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image,support_set]\n",
        "\n",
        "    return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3OedJdVzYoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(os.path.join(model_path, \"weights.h5\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocRWv1QSzumQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "t_start = time.time()\n",
        "for i in range(1, n_iter+1):\n",
        "    (inputs,targets) = prepare_batch(batch_size)\n",
        "    print(len(inputs), len(targets))\n",
        "    loss = model.train_on_batch(inputs, targets)\n",
        "    if i % 10 == 0: #evaluate_every\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
        "        print(\"Train Loss: {0}\".format(loss)) \n",
        "        #val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
        "        model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
        "        #if val_acc >= best:\n",
        "        #    print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
        "        #    best = val_acc\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}